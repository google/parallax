{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "mC6PjgDWhJlX",
      "metadata": {
        "id": "mC6PjgDWhJlX"
      },
      "source": [
        "# Model Offloading Demo\n",
        "\n",
        "This notebook demonstrates using model offloading to train a model that is so large that its forward pass would otherwise not fit into HBM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "20fe5cd4-9ce6-4c75-9fbe-015a869e995f",
      "metadata": {
        "executionInfo": {
          "elapsed": 12281,
          "status": "ok",
          "timestamp": 1758646160401,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "20fe5cd4-9ce6-4c75-9fbe-015a869e995f"
      },
      "outputs": [],
      "source": [
        "from etils import ecolab\n",
        "import flax.nnx as nnx\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import optax\n",
        "\n",
        "with ecolab.adhoc(reload='parallax'):\n",
        "  import parallax\n",
        "  from parallax.examples import models\n",
        "  from parallax.examples import utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b-ymwMLbQxwj",
      "metadata": {
        "executionInfo": {
          "elapsed": 2377,
          "status": "ok",
          "timestamp": 1758646162985,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "b-ymwMLbQxwj",
        "outputId": "4d3dc814-1683-41ce-dc9c-0dcaa4be13e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:2025-09-23 09:49:21,408:jax._src.xla_bridge:822: Unable to initialize backend 'tpu': UNKNOWN: TPU initialization failed: No jellyfish device found.\n",
            "INFO:2025-09-23 09:49:21,410:jax._src.xla_bridge:822: Unable to initialize backend 'pathways': Could not initialize backend 'pathways'\n",
            "INFO:2025-09-23 09:49:21,411:jax._src.xla_bridge:822: Unable to initialize backend 'proxy': INVALID_ARGUMENT: IFRT proxy server address must be '<transport-type>://<backend-address>' (e.g., 'grpc://localhost'), but got \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All devices: [CudaDevice(id=0)]\n",
            "{'num_allocs': 0, 'bytes_in_use': 0, 'peak_bytes_in_use': 0, 'largest_alloc_size': 0, 'bytes_limit': 31724126208, 'bytes_reserved': 0, 'peak_bytes_reserved': 0, 'largest_free_block_bytes': 0, 'pool_bytes': 0, 'peak_pool_bytes': 0}\n"
          ]
        }
      ],
      "source": [
        "print('All devices:', jax.devices())\n",
        "gpu_device = jax.devices('gpu')[0]\n",
        "print(gpu_device.memory_stats())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "ogRgCC6yQ4Xa",
      "metadata": {
        "executionInfo": {
          "elapsed": 17811,
          "status": "ok",
          "timestamp": 1758646381547,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "ogRgCC6yQ4Xa",
        "outputId": "c8c09d12-0e28-4a37-ea57-7d6f5640723e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TFRT_CPU_0\n"
          ]
        }
      ],
      "source": [
        "# Define models.\n",
        "VOCAB_SIZE = 10_000\n",
        "MAX_LEN = 1024\n",
        "\n",
        "model = parallax.create_offloaded_model(\n",
        "    lambda: models.MiniGPT7B(VOCAB_SIZE, nnx.Rngs(42), MAX_LEN),\n",
        ")\n",
        "print(model.layers[1].linear1.kernel.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "KpDVxXiqRLuA",
      "metadata": {
        "executionInfo": {
          "elapsed": 47541,
          "status": "ok",
          "timestamp": 1758646430968,
          "user": {
            "displayName": "",
            "userId": ""
          },
          "user_tz": 420
        },
        "id": "KpDVxXiqRLuA",
        "outputId": "5ff10c89-81f3-493b-8c4d-20b3fc2a3cb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Array([[[-1.80469, 0.0622559, -0.503906, ..., 0.59375, -0.617188,\n",
              "         0.0981445],\n",
              "        [-1.80469, 0.0625, -0.503906, ..., 0.589844, -0.613281,\n",
              "         0.0917969],\n",
              "        [-1.79688, 0.0629883, -0.5, ..., 0.59375, -0.617188, 0.0883789],\n",
              "        ...,\n",
              "        [-1.83594, 0.109863, -0.542969, ..., 0.582031, -0.621094,\n",
              "         0.0141602],\n",
              "        [-1.83594, 0.109375, -0.542969, ..., 0.578125, -0.617188,\n",
              "         0.0185547],\n",
              "        [-1.83594, 0.11377, -0.546875, ..., 0.574219, -0.617188,\n",
              "         0.0113525]],\n",
              "\n",
              "       [[-1.80469, 0.0622559, -0.503906, ..., 0.59375, -0.617188,\n",
              "         0.0981445],\n",
              "        [-1.80469, 0.0625, -0.503906, ..., 0.589844, -0.613281,\n",
              "         0.0917969],\n",
              "        [-1.79688, 0.0629883, -0.5, ..., 0.59375, -0.617188, 0.0883789],\n",
              "        ...,\n",
              "        [-1.83594, 0.109863, -0.542969, ..., 0.582031, -0.621094,\n",
              "         0.0141602],\n",
              "        [-1.83594, 0.109375, -0.542969, ..., 0.578125, -0.617188,\n",
              "         0.0185547],\n",
              "        [-1.83594, 0.11377, -0.546875, ..., 0.574219, -0.617188,\n",
              "         0.0113525]],\n",
              "\n",
              "       [[-1.80469, 0.0622559, -0.503906, ..., 0.59375, -0.617188,\n",
              "         0.0981445],\n",
              "        [-1.80469, 0.0625, -0.503906, ..., 0.589844, -0.613281,\n",
              "         0.0917969],\n",
              "        [-1.79688, 0.0629883, -0.5, ..., 0.59375, -0.617188, 0.0883789],\n",
              "        ...,\n",
              "        [-1.83594, 0.109863, -0.542969, ..., 0.582031, -0.621094,\n",
              "         0.0141602],\n",
              "        [-1.83594, 0.109375, -0.542969, ..., 0.578125, -0.617188,\n",
              "         0.0185547],\n",
              "        [-1.83594, 0.11377, -0.546875, ..., 0.574219, -0.617188,\n",
              "         0.0113525]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-1.80469, 0.0622559, -0.503906, ..., 0.59375, -0.617188,\n",
              "         0.0981445],\n",
              "        [-1.80469, 0.0625, -0.503906, ..., 0.589844, -0.613281,\n",
              "         0.0917969],\n",
              "        [-1.79688, 0.0629883, -0.5, ..., 0.59375, -0.617188, 0.0883789],\n",
              "        ...,\n",
              "        [-1.83594, 0.109863, -0.542969, ..., 0.582031, -0.621094,\n",
              "         0.0141602],\n",
              "        [-1.83594, 0.109375, -0.542969, ..., 0.578125, -0.617188,\n",
              "         0.0185547],\n",
              "        [-1.83594, 0.11377, -0.546875, ..., 0.574219, -0.617188,\n",
              "         0.0113525]],\n",
              "\n",
              "       [[-1.80469, 0.0622559, -0.503906, ..., 0.59375, -0.617188,\n",
              "         0.0981445],\n",
              "        [-1.80469, 0.0625, -0.503906, ..., 0.589844, -0.613281,\n",
              "         0.0917969],\n",
              "        [-1.79688, 0.0629883, -0.5, ..., 0.59375, -0.617188, 0.0883789],\n",
              "        ...,\n",
              "        [-1.83594, 0.109863, -0.542969, ..., 0.582031, -0.621094,\n",
              "         0.0141602],\n",
              "        [-1.83594, 0.109375, -0.542969, ..., 0.578125, -0.617188,\n",
              "         0.0185547],\n",
              "        [-1.83594, 0.11377, -0.546875, ..., 0.574219, -0.617188,\n",
              "         0.0113525]],\n",
              "\n",
              "       [[-1.80469, 0.0622559, -0.503906, ..., 0.59375, -0.617188,\n",
              "         0.0981445],\n",
              "        [-1.80469, 0.0625, -0.503906, ..., 0.589844, -0.613281,\n",
              "         0.0917969],\n",
              "        [-1.79688, 0.0629883, -0.5, ..., 0.59375, -0.617188, 0.0883789],\n",
              "        ...,\n",
              "        [-1.83594, 0.109863, -0.542969, ..., 0.582031, -0.621094,\n",
              "         0.0141602],\n",
              "        [-1.83594, 0.109375, -0.542969, ..., 0.578125, -0.617188,\n",
              "         0.0185547],\n",
              "        [-1.83594, 0.11377, -0.546875, ..., 0.574219, -0.617188,\n",
              "         0.0113525]]], dtype=bfloat16)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mesh = jax.make_mesh((1,), ('x',))\n",
        "s_host = jax.sharding.NamedSharding(\n",
        "    mesh,\n",
        "    jax.sharding.PartitionSpec(None),\n",
        "    memory_kind='pinned_host',\n",
        ")\n",
        "jitted_model_call = parallax.jit_offloaded_model(model, s_host)\n",
        "\n",
        "# The state of the model must be on the host to begin with.\n",
        "state = nnx.state(model)\n",
        "host_state = jax.tree.map(lambda x: jax.device_put(x, s_host), state)\n",
        "\n",
        "# 3. Run the forward pass with offloading.\n",
        "inputs, _ = utils.make_gpt_inputs(batch_size=8, max_len=MAX_LEN)\n",
        "outputs = jitted_model_call(host_state, inputs)\n",
        "outputs"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "last_runtime": {
        "build_target": "//third_party/py/parallax/notebooks:colab",
        "kind": "private"
      },
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
